---
title: "write up business final"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Abstract

*outline problem*
One of the largest obstacles 

*mention models*



## Introduction and background

Identifying customers who will purchase a product after visitng a website is one of the most important factors in online commerce. The Pareto Principle, a business principle that asserts 80% of outcomes result from 20% of causes . In our case this means that we would expect 80% of the revenue to be generated by 20% of the customers [1]. The data from the Gstore contains X variables for around 900,000 site visits. A rigorous investigation of these determinants is needed to identify if this rule of thumb holds, and which customers marketing resources should be put towards. 

The Pareto Principle was developed by Italian economist Vilfredo Pareto, who discovered that 80% of the land in Italy was owned by 20% of the population. This is a description of a power law distribution, known as the Pareto distribution. It has been found that natural phenomena exhibit this distribution, particulary in commerce. This was translated to business administration by consultant Joseph M. Juran, who urges decision makers to find "their golden 20%".[1] Where they can make actionable statements like "These are my top transaction locations" or "these are my top traffic channels for revenue generation."

A lay approach to identifying the golden 20% is to graph a single categorical variable and identify which category most of the revenue was generated from. (chart 1) This however makes it more difficult to address variable interaction. 


The purpose of this paper is to generate a multivariate model of transaction behavior of the Gstore visitors so that we can identify customers most likely to generate revenue using data from the Google Gstore. In particular, it develops a Random Forest model to predict the revenue generated by a specific transaction.  Random Forest Regression is a supervised learning algorithm that uses ensemble learning method for regression. Ensemble learning method is a technique that combines predictions from multiple machine learning algorithms to make a more accurate prediction than a single model. We will compare this with a generalized linear model that generalizes linear regression by allowing the linear model to be related to the response variable via a link function (gaussian) and by allowing the magnitude of the variance of each measurement to be a function of its predicted value. 

Each model is evaluated using the Root Mean Squared Error (RMSE) function. The model with the lowest RMSE is chosen.

This paper reports which factors we deem to be the most important, providing insights for a better decision making model for how to target specific customers to an online store. 

The organization of this paper will be:
-description of the methodological framework
-description of the Gstore data
-empirical results of the modeling
-conculsions drawn from our findings

## Methodology



Modeling transaction revenue can be either broken down as a two step process (identifying discrete outcomes, then modeling revenue of the positive class) , or creating a randomForest regression model 

We expect Random Forest modeling to work better if: 
1.
The underlying function is not truly linear
2.
We end up selecting a high number of predictor variables
3.
There is high covariate shift (the distributions shift between the train and the test set)[6]

While the Random Forest Regression seems like the best fit for our data, we will employ the 'no free lunch' theorem [7] and generate linear models as well for comparison. 

We will be predicting the natural log of the sum of all transactions per user (further discussed in the data section) 
$$y_{user} = \sum_{i=1}^{n} transaction_{user_i}$$

$$target_{user} = \ln({y_{user}+1})$$

## Data

Data analyized in this paper as collected from *TIMEFRAME* for assesment of the Gstore. The data provided is for all visitors to the Google gstore during this period.


There are almost 1 million rows and 55 columns once unpacked, The following is a description of the most consequential columns from the data. 

fullVisitorId:
- A unique identifier for each user of the Google Merchandise Store. This will be important for summing each transactors behavior since it is constant between a users unique visits over time. 
channelGrouping:
- The channel via which the user came to the Store.  *WHAT IS A CHANNEL*
date:
- The date on which the user visited the Store.
device:
- The specifications for the device used to access the Store, such as tablet, phone or desktop. 
geoNetwork:
- This section contains information about the geography of the user, such as the country, state and city from which they accessed the store. 
socialEngagementType:
-Engagement type, either "Socially Engaged" or "Not Socially Engaged", referring to social media usage
totals:
-This section contains aggregate values across the session.
trafficSource:
-This section contains information about the Traffic Source from which the session originated.
visitId:
- An identifier for this session. This is part of the value usually stored as the _utmb cookie. This is only unique to the user. For a completely unique ID, you should use a combination of fullVisitorId and visitId.
visitNumber:
- The session number for this user. If this is the first session, then this is set to 1.
visitStartTime:
- The timestamp (expressed as POSIX time).
hits:
- This row and nested fields are populated for any and all types of hits. Provides a record of all page visits.
customDimensions:
- This section contains any user-level or session-level custom dimensions that are set for a session. This is a repeated field and has an entry for each dimension that is set.
totals - This set of columns mostly includes high-level aggregate data

The most notable transformation that is employed is the natural log of the target revenue. As shown in in chart 2, the transactions are on the whole all zero, causing a severe right skew. Taking the log of revenue makes the data more normally distributed, allowing for more precise analysis. This also gives us our first insights into finding the golden 20%, since most of the visitors to the Gstore are not revenue generators. 

Another notable feature of the data is that 40% of the variables are either sparse or only contain one value, which can be excluded from our analysis for conatining no row-wise information. 

## Empirical Results


Table 1 is the correlation matrix of the variables included in the modeling. A correlation matrix will give decision makers an intuitive understanding of the different factors on purchasing behavior, as well as indication of possible predictors for revenue generating transactors. For example, GIVE A STRONG INDICATOR WITH REVENUE. On the other hand, SOMETHING THAT ISN'T CORRELATED.

In Table 2, we show the differences in in estimation between a GLM  and a Random Forest Regression. In this table we report the estimation results of both models.  THE RSS metric reports the WHAT IT MEAUSRES and can be calculated as the following

RSS ESTIMATOR EQUATION. 


WHAT OUR MODEL SAYS ABOUT THE IMPORTANT VARIABLES

REALLY DIG INTO WHAT VARIABLES ARE IMPROTANT AND THE INTUTION BEHIND IT


## Summary and Conclusions

In this paper, we compare the results of a GLM and Random Forest Regression model on the likelihood of a Gstore visitor to be a revenue generator.  

Several important factors are found to influence a Gstore visitor's decision to make a purchase. These factors include LIST IMPORTANT FACTORS. 

This study generates useful insights for a better understanding of customer behavior on the Google Gstore. For decision makers, this could lead to more targeted marketing, and even what data is important to collect from a visitor to an online market. 


## References

[1] Carla Tardi, 2020. 80-20 Rule. https://www.investopedia.com/terms/1/80-20-rule.asp

[6] https://www.seldon.io/what-is-covariate-shift/#:~:text=Covariate%20shift%20is%20a%20specific,training%20environment%20and%20live%20environment.&text=Covariate%20shift%20is%20also%20known,issue%20encountered%20in%20machine%20learning.

[7] https://machinelearningmastery.com/no-free-lunch-theorem-for-machine-learning/